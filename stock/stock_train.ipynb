{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:12.944896Z",
          "iopub.execute_input": "2022-11-08T13:26:12.945510Z",
          "iopub.status.idle": "2022-11-08T13:26:13.987587Z",
          "shell.execute_reply.started": "2022-11-08T13:26:12.945450Z",
          "shell.execute_reply": "2022-11-08T13:26:13.986024Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3JCVQ7I_Neg",
        "outputId": "08ed01cc-f336-4614-a792-28431450bde9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 21 05:37:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BlLfN3S8e6U",
        "outputId": "1db280bf-2740-4f7e-ef34-88bae248b1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "id": "pFUfv-54i9Sa",
        "outputId": "82efeb4f-f289-4487-81dd-82598fae9ce7",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:25:59.567828Z",
          "iopub.execute_input": "2022-11-08T13:25:59.568988Z",
          "iopub.status.idle": "2022-11-08T13:26:12.941435Z",
          "shell.execute_reply.started": "2022-11-08T13:25:59.568942Z",
          "shell.execute_reply": "2022-11-08T13:26:12.939502Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ ! -e \"stocks\" ]; then \\\n",
        "  gdown --id '1AzIra9nVKVnXEg4RDi6Dtqtr9nZergzH' --output \"stocks.zip\" ;\\\n",
        "  unzip -q \"stocks.zip\" ;\\\n",
        "fi\n",
        "\n",
        "!rm stocks.zip"
      ],
      "metadata": {
        "id": "IT6lNY75B3AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1517dd2-997d-45fe-e900-02396330ad4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AzIra9nVKVnXEg4RDi6Dtqtr9nZergzH\n",
            "From (redirected): https://drive.google.com/uc?id=1AzIra9nVKVnXEg4RDi6Dtqtr9nZergzH&confirm=t&uuid=5a7ed48f-770d-450a-84e6-3cd236f6ed42\n",
            "To: /content/stocks.zip\n",
            "100% 52.4M/52.4M [00:00<00:00, 70.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 x 5\n",
        "\n",
        "# !if [ ! -e \"stock_dataset\" ]; then \\\n",
        "#   gdown --id '1XtdsevhmWB_jAGR89QxupIXdlDDdPlt_' --output \"stock_dataset.zip\" ;\\\n",
        "#   unzip -q \"stock_dataset.zip\" ;\\\n",
        "# fi\n",
        "\n",
        "# !rm stock_dataset.zip"
      ],
      "metadata": {
        "id": "99aGcN5xog7x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 x 6\n",
        "\n",
        "# !if [ ! -e \"stock_dataset\" ]; then \\\n",
        "#   gdown --id '175wsxX4Wad3otXWHPnFuVlnvweeffP9N' --output \"stock_dataset.zip\" ;\\\n",
        "#   unzip -q \"stock_dataset.zip\" ;\\\n",
        "# fi\n",
        "\n",
        "# !rm stock_dataset.zip"
      ],
      "metadata": {
        "id": "Bo0zCp3lcs3S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 x 7\n",
        "\n",
        "!if [ ! -e \"stock_dataset\" ]; then \\\n",
        "  gdown --id '1oEBl2rVCSKP0Qg13YhWHAfG5ZAdkYZnr' --output \"stock_dataset.zip\" ;\\\n",
        "  unzip -q \"stock_dataset.zip\" ;\\\n",
        "fi\n",
        "\n",
        "!rm stock_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3972f8c5-0c34-43c6-c7fa-513db28f2bae",
        "id": "uJlJ-cKuctKa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1oEBl2rVCSKP0Qg13YhWHAfG5ZAdkYZnr\n",
            "From (redirected): https://drive.google.com/uc?id=1oEBl2rVCSKP0Qg13YhWHAfG5ZAdkYZnr&confirm=t&uuid=ff64373b-393e-494d-9367-5cdd9f4f5282\n",
            "To: /content/stock_dataset.zip\n",
            "100% 891M/891M [00:11<00:00, 76.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ ! -e \"stock_num.txt\" ]; then \\\n",
        "  gdown --id '1uVUmGb5TG1XNPKfiipZZ8CZZvHkiz33_' --output \"stock_num.txt\" ;\\\n",
        "fi"
      ],
      "metadata": {
        "id": "RdN-JZMJ_cGG",
        "outputId": "a0453689-da23-4656-d521-5b1b4bfe4c65",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:13.989800Z",
          "iopub.execute_input": "2022-11-08T13:26:13.990797Z",
          "iopub.status.idle": "2022-11-08T13:26:15.033316Z",
          "shell.execute_reply.started": "2022-11-08T13:26:13.990732Z",
          "shell.execute_reply": "2022-11-08T13:26:15.031706Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uVUmGb5TG1XNPKfiipZZ8CZZvHkiz33_\n",
            "To: /content/stock_num.txt\n",
            "100% 12.0k/12.0k [00:00<00:00, 29.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# For Progress Bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset, SubsetRandomSampler\n",
        "\n",
        "from transformers import get_scheduler\n",
        "from accelerate import Accelerator, DistributedDataParallelKwargs, InitProcessGroupKwargs\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "# KFold\n",
        "# KFOLD Reference: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "PgBXnwiNjgvV",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:15.037762Z",
          "iopub.execute_input": "2022-11-08T13:26:15.038501Z",
          "iopub.status.idle": "2022-11-08T13:26:15.048343Z",
          "shell.execute_reply.started": "2022-11-08T13:26:15.038434Z",
          "shell.execute_reply": "2022-11-08T13:26:15.046849Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_num = list()\n",
        "with open('stock_num.txt') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        stock_num.append(line.strip())"
      ],
      "metadata": {
        "id": "dniOWWe1s5h9",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:15.050509Z",
          "iopub.execute_input": "2022-11-08T13:26:15.051055Z",
          "iopub.status.idle": "2022-11-08T13:26:15.066848Z",
          "shell.execute_reply.started": "2022-11-08T13:26:15.051004Z",
          "shell.execute_reply": "2022-11-08T13:26:15.065515Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_num_mod = []\n",
        "for i in range(len(stock_num)):\n",
        "    path = 'stocks/' + stock_num[i] + '.csv'\n",
        "    try:\n",
        "        stock = pd.read_csv(path)\n",
        "        if len(stock) >= 500:\n",
        "            stock_num_mod.append(stock_num[i])\n",
        "    except:\n",
        "        print(path, \" is empty and has been skipped.\")\n",
        "\n",
        "print(len(stock_num_mod))"
      ],
      "metadata": {
        "id": "FGqKZ3Drjz2z",
        "outputId": "59461489-34eb-4f32-c4af-71f322c0fdec",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:16.087837Z",
          "iopub.execute_input": "2022-11-08T13:26:16.089220Z",
          "iopub.status.idle": "2022-11-08T13:26:19.211554Z",
          "shell.execute_reply.started": "2022-11-08T13:26:16.089158Z",
          "shell.execute_reply": "2022-11-08T13:26:19.210155Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def same_seed(seed):\n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    '''Split provided training data into training set and validation set'''\n",
        "    valid_set_size = int(valid_ratio * len(data_set))\n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "            preds.append(pred.detach().cpu())\n",
        "    preds = torch.cat(preds, dim=0).numpy()\n",
        "    return preds"
      ],
      "metadata": {
        "id": "7PveUY_FmAlM",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:20.345695Z",
          "iopub.execute_input": "2022-11-08T13:26:20.346224Z",
          "iopub.status.idle": "2022-11-08T13:26:20.357651Z",
          "shell.execute_reply.started": "2022-11-08T13:26:20.346180Z",
          "shell.execute_reply": "2022-11-08T13:26:20.356271Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py"
      ],
      "metadata": {
        "id": "YVZg_4-LfDZR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, feature_dim=5, d_model=128, nhead=8, num_layers=4, dropout=0.1):\n",
        "        super(My_Model, self).__init__()\n",
        "        self.embedding = nn.Linear(feature_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),  # Binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, feature_dim]\n",
        "        x = self.embedding(x)               # [batch_size, seq_len, d_model]\n",
        "        x = self.positional_encoding(x)     # Add positional encoding\n",
        "        x = self.transformer_encoder(x)     # [batch_size, seq_len, d_model]\n",
        "        x = x.mean(dim=1)                   # Mean pooling over time\n",
        "        logits = self.classifier(x)         # [batch_size, 1]\n",
        "        return torch.sigmoid(logits)        # Output in [0, 1] range\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # even index\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # odd index\n",
        "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, d_model]\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "24JpIPBipoOt",
        "execution": {
          "iopub.status.busy": "2022-11-08T13:26:24.348461Z",
          "iopub.execute_input": "2022-11-08T13:26:24.348995Z",
          "iopub.status.idle": "2022-11-08T13:26:24.360361Z",
          "shell.execute_reply.started": "2022-11-08T13:26:24.348952Z",
          "shell.execute_reply": "2022-11-08T13:26:24.358471Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockDataset(Dataset):\n",
        "    '''\n",
        "    x: Features.\n",
        "    y: Targets, if none, do prediction.\n",
        "    '''\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(np.asarray(y))\n",
        "        self.x = torch.FloatTensor(np.asarray(x))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "LeakkuY59xXX",
        "execution": {
          "iopub.status.busy": "2022-11-08T14:02:05.051098Z",
          "iopub.execute_input": "2022-11-08T14:02:05.051608Z",
          "iopub.status.idle": "2022-11-08T14:02:05.060922Z",
          "shell.execute_reply.started": "2022-11-08T14:02:05.051569Z",
          "shell.execute_reply": "2022-11-08T14:02:05.059263Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.file = h5py.File(filepath, 'r')\n",
        "        self.data = self.file['data']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # You can convert to torch.Tensor if needed\n",
        "        return torch.tensor(self.data[idx], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "gF066Pigo7OO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = h5py.File('stock_dataset/train_dataset.h5', 'r')['data']\n",
        "Y_train = h5py.File('stock_dataset/train_groud_truth.h5', 'r')['data']\n",
        "X_dev = h5py.File('stock_dataset/val_dataset.h5', 'r')['data']\n",
        "Y_dev = h5py.File('stock_dataset/val_groud_truth.h5', 'r')['data']\n",
        "X_test = h5py.File('stock_dataset/test_dataset.h5', 'r')['data']"
      ],
      "metadata": {
        "id": "I4ZuHtHKpBzF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 42,      # Your seed number, you can pick your lucky number. :)\n",
        "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 2000,     # Number of epochs.\n",
        "    'batch_size': 64,\n",
        "    'warmup_steps': 2000,\n",
        "    'lr_schedule': 'cosine',\n",
        "    'learning_rate': 2e-4,\n",
        "    'weight_decay': 1e-6,\n",
        "    'betas': (0.9, 0.99),\n",
        "    'early_stop': 200,    # If model has not improved for this many consecutive epochs, stop training.\n",
        "    'clip_grad_norm': 0.1,\n",
        "    'k_folds': 5,\n",
        "    # 'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
        "    'save_path': './models/'\n",
        "}"
      ],
      "metadata": {
        "id": "A2jX4xmM9FP-",
        "execution": {
          "iopub.status.busy": "2022-11-08T14:02:03.016088Z",
          "iopub.execute_input": "2022-11-08T14:02:03.016573Z",
          "iopub.status.idle": "2022-11-08T14:02:03.024830Z",
          "shell.execute_reply.started": "2022-11-08T14:02:03.016535Z",
          "shell.execute_reply": "2022-11-08T14:02:03.023143Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "same_seed(config['seed'])\n",
        "#train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "# Print out the data size.\n",
        "print(f\"\"\"train_data size: {X_train.shape}\n",
        "valid_data size: {X_dev.shape}\n",
        "test_data size: {X_test.shape}\"\"\")\n",
        "\n",
        "# Select features\n",
        "#x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
        "\n",
        "# Print out the number of features.\n",
        "print(f'number of features: {X_train.shape[1:]}')\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = StockDataset(X_train, Y_train), \\\n",
        "                                            StockDataset(X_dev, Y_dev), \\\n",
        "                                            StockDataset(X_test)\n",
        "\n",
        "# For KFold\n",
        "dataset = ConcatDataset([train_dataset, valid_dataset])\n",
        "\n",
        "# Pytorch data loader loads pytorch dataset into batches.\n",
        "# Without KFold\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "6KNfU18t9S8e",
        "execution": {
          "iopub.status.busy": "2022-11-08T14:02:07.745260Z",
          "iopub.execute_input": "2022-11-08T14:02:07.745748Z",
          "iopub.status.idle": "2022-11-08T14:02:07.759609Z",
          "shell.execute_reply.started": "2022-11-08T14:02:07.745710Z",
          "shell.execute_reply": "2022-11-08T14:02:07.757927Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f2fde0-5e75-41b5-ad83-2181cdf10795"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data size: (781600, 20, 7)\n",
            "valid_data size: (195400, 20, 7)\n",
            "test_data size: (1954, 20, 7)\n",
            "number of features: (20, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "\n",
        "init_process_kwargs = InitProcessGroupKwargs(timeout=timedelta(minutes=90))\n",
        "\n",
        "accelerator = Accelerator(\n",
        "        mixed_precision = 'no',\n",
        "        kwargs_handlers=[ddp_kwargs, init_process_kwargs]\n",
        ")"
      ],
      "metadata": {
        "id": "fpvVlf8yrljT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(fold, train_loader, valid_loader, model, config, optimizer, lr_scheduler, device):\n",
        "\n",
        "    #criterion = nn.MSELoss(size_average=True)\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    #sigmoid = nn.Sigmoid()\n",
        "    # Define your optimization algorithm.\n",
        "    # Check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
        "    # L2 regularization (optimizer(weight decay...) or implement by your self).\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9, weight_decay=config['weight_decay'])\n",
        "\n",
        "\n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "        correct = 0\n",
        "        val_correct = 0\n",
        "        # tqdm is a package to visualize your training progress.\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for x, y in train_pbar:\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device.\n",
        "            pred = model(x)\n",
        "            #print(f'pred size : {pred.shape}')\n",
        "            #print(f'y size : {y.shape}')\n",
        "            loss = criterion(pred, y)\n",
        "            accelerator.backward(loss)                     # Compute gradient(backpropagation).\n",
        "            accelerator.clip_grad_norm_(model.parameters(), config['clip_grad_norm'])\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            accelerator.wait_for_everyone()\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "\n",
        "            # For MSELoss\n",
        "            #correct += (pred == y.T).float().sum()\n",
        "\n",
        "            # For BCEWithLogitsLoss\n",
        "            #print(\"y = \", y)\n",
        "            #print(\"pred = \", pred)\n",
        "            pred = pred > 0.5\n",
        "            correct += (pred == y).float().sum()\n",
        "            #print(\"correct = \", correct)\n",
        "\n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "        #print('correct = ', correct)\n",
        "        accuracy = 100 * correct / X_train.shape[0]\n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "                # For MSELoss\n",
        "                #val_correct += (pred == y.T).float().sum()\n",
        "\n",
        "                # For BCEWithLogitsLoss\n",
        "                #print(\"y = \", y)\n",
        "                #print(\"pred = \", pred)\n",
        "                pred = pred > 0.5\n",
        "                val_correct += (pred == y).float().sum()\n",
        "\n",
        "            loss_record.append(loss.item())\n",
        "\n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "        val_accuracy = 100 * val_correct / X_dev.shape[0]\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train Acc: {accuracy:.4f}, Valid Acc: {val_accuracy:.4f}')\n",
        "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            torch.save(model.state_dict(), config['save_path'] + fold + '_model.ckpt') # Save your best model\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "            early_stop_count = 0\n",
        "        else:\n",
        "            early_stop_count += 1\n",
        "\n",
        "        if early_stop_count >= config['early_stop']:\n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            print('\\nBest Loss = ' + str(best_loss))\n",
        "            return"
      ],
      "metadata": {
        "id": "3xLMytuZ9Lvt",
        "execution": {
          "iopub.status.busy": "2022-11-08T14:02:09.979139Z",
          "iopub.execute_input": "2022-11-08T14:02:09.979550Z",
          "iopub.status.idle": "2022-11-08T14:02:09.999619Z",
          "shell.execute_reply.started": "2022-11-08T14:02:09.979515Z",
          "shell.execute_reply": "2022-11-08T14:02:09.998522Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = My_Model(feature_dim=X_train.shape[-1]).to(device) # put your model and data on the same computation device.\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], betas = config['betas'], weight_decay=config['weight_decay'])\n",
        "lr_scheduler = get_scheduler(\n",
        "        config['lr_schedule'],\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=config['warmup_steps'],\n",
        "        num_training_steps=config['n_epochs']*len(train_loader),\n",
        ")\n",
        "model, optimizer, train_loader, valid_loader, lr_scheduler = accelerator.prepare(model, optimizer, train_loader, valid_loader, lr_scheduler)\n",
        "trainer('none', train_loader, valid_loader, model, config, optimizer, lr_scheduler, device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-08T14:02:13.688408Z",
          "iopub.execute_input": "2022-11-08T14:02:13.688935Z",
          "iopub.status.idle": "2022-11-08T14:03:17.099248Z",
          "shell.execute_reply.started": "2022-11-08T14:02:13.688897Z",
          "shell.execute_reply": "2022-11-08T14:03:17.097810Z"
        },
        "trusted": true,
        "id": "rMfMSlnL_Nel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3281bd22-9bcf-4859-b6e6-e6f0b85a28a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/2000]: 100%|██████████| 12213/12213 [03:32<00:00, 57.53it/s, loss=0.693]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2000]: Train loss: 0.6935, Valid loss: 0.6931\n",
            "Epoch [1/2000]: Train Acc: 55.8756, Valid Acc: 55.6919\n",
            "Saving model with loss 0.693...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/2000]: 100%|██████████| 12213/12213 [03:21<00:00, 60.69it/s, loss=0.693]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2000]: Train loss: 0.6931, Valid loss: 0.6931\n",
            "Epoch [2/2000]: Train Acc: 55.8753, Valid Acc: 55.6919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/2000]:  50%|████▉     | 6072/12213 [01:43<03:15, 31.38it/s, loss=0.693]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'raise'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([stock_num_mod[i], p])\n",
        "\n",
        "model = My_Model(feature_dim=X_train.shape[-1]).to(device)\n",
        "model.load_state_dict(torch.load(config['save_path'] + 'none_model.ckpt'))\n",
        "preds = predict(test_loader, model, device)\n",
        "preds = preds > 0.5\n",
        "save_pred(preds, 'none_pred.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-08T14:03:17.102066Z",
          "iopub.execute_input": "2022-11-08T14:03:17.102505Z",
          "iopub.status.idle": "2022-11-08T14:03:17.125623Z",
          "shell.execute_reply.started": "2022-11-08T14:03:17.102466Z",
          "shell.execute_reply": "2022-11-08T14:03:17.124144Z"
        },
        "trusted": true,
        "id": "FbLYERzF_Nel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KFold testing\n",
        "model = My_Model(feature_dim=X_train.shape[-1]).to(device) # put your model and data on the same computation device.\n",
        "kfold = KFold(n_splits=config['k_folds'], shuffle=True)\n",
        "\n",
        "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    train_subsampler = SubsetRandomSampler(train_ids)\n",
        "    valid_subsampler = SubsetRandomSampler(valid_ids)\n",
        "    train_loader = DataLoader(dataset, batch_size=config['batch_size'], sampler=train_subsampler,\n",
        "                              num_workers=0, pin_memory=True)\n",
        "    valid_loader = DataLoader(dataset, batch_size=config['batch_size'], sampler=valid_subsampler,\n",
        "                              num_workers=0, pin_memory=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], betas = config['betas'], weight_decay=config['weight_decay'])\n",
        "    lr_scheduler = get_scheduler(\n",
        "                config['lr_schedule'],\n",
        "                optimizer=optimizer,\n",
        "                num_warmup_steps=config['warmup_steps'],\n",
        "                num_training_steps=config['n_epochs']*len(train_loader),\n",
        "    )\n",
        "\n",
        "    model, optimizer, train_loader, valid_loader, lr_scheduler = accelerator.prepare(model, optimizer, train_loader, valid_loader, lr_scheduler)\n",
        "\n",
        "    trainer('Fold_' + str(fold),train_loader, valid_loader, model, config, optimizer, lr_scheduler, device)\n",
        "\n",
        "    model.load_state_dict(torch.load(config['save_path'] + 'Fold_' + str(fold) + '_model.ckpt'))\n",
        "    preds = predict(test_loader, model, device)\n",
        "    preds = preds > 0.5\n",
        "    save_pred(preds, 'Fold_' + str(fold) + '_pred.csv')"
      ],
      "metadata": {
        "id": "2YsWTYZE_EZe",
        "execution": {
          "iopub.status.busy": "2022-11-08T14:03:17.127340Z",
          "iopub.execute_input": "2022-11-08T14:03:17.127794Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}